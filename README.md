ğŸ–¼ï¸ğŸ¤ AI Image Caption + Voice Generator (Free Version)
ğŸš€ Overview

AI Image Caption + Voice Generator is a free and open-source app that uses AI vision models to describe any image and then speaks the caption aloud using text-to-speech.

It combines:

ğŸ§  OpenRouter (GPT-4o-mini) for smart image-to-text captioning

ğŸ¤ Google TTS (gTTS) for realistic voice output

âš™ï¸ FastAPI backend

ğŸ’» Streamlit frontend

Everything runs 100% free â€” no paid APIs required!

ğŸ¯ Features

âœ… Upload any image (JPG, PNG, WEBP)
âœ… Generates a meaningful one-line caption using AI
âœ… Converts the caption into an MP3 voice automatically
âœ… Simple, clean Streamlit interface
âœ… Built entirely with open and free technologies

ğŸ§  Tech Stack
Layer	Technology
Frontend	Streamlit
Backend	FastAPI
AI Model	OpenRouter (gpt-4o-mini)
Text-to-Speech	gTTS (Google Text-to-Speech)
Environment	Python + dotenv
Communication	REST API (JSON)

ğŸ—ï¸ Project Structure
AI Image Caption Generator/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ caption_gen_openrouter.py
â”‚   â”œâ”€â”€ tts_voice.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ temp/
â”‚
â”œâ”€â”€ app.py
â”‚
â”œâ”€â”€ .env
â””â”€â”€ requirements.txt

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/YOUR_USERNAME/ai-image-caption-voice-generator.git
cd ai-image-caption-voice-generator

2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
venv\Scripts\activate  # (Windows)
# or
source venv/bin/activate  # (Mac/Linux)

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Your .env File

Create a file named .env in the root directory and paste:

OPENROUTER_API_KEY=your_openrouter_api_key_here
MODEL=openai/gpt-4o-mini


ğŸ§© Get your free key from OpenRouter.ai

5ï¸âƒ£ Start the Backend
uvicorn backend.main:app --reload


Visit ğŸ‘‰ http://127.0.0.1:8000/docs
 to test endpoints.

6ï¸âƒ£ Start the Frontend

In a new terminal:

cd frontend
streamlit run app.py


Your app will open at ğŸ‘‰ http://localhost:8501

ğŸ§© Example Output
Image Input	AI Caption	Voice Output
ğŸ–¼ï¸ Eiffel Tower	â€œA beautiful view of the Eiffel Tower against a clear blue sky.â€	ğŸ”Š Spoken via gTTS
ğŸ¶ Dog	â€œA happy golden retriever playing on green grass.â€	ğŸ”Š Spoken via gTTS
ğŸŒ‡ City Sunset	â€œA breathtaking sunset illuminating the modern city skyline.â€	ğŸ”Š Spoken via gTTS

ğŸ“¦ Requirements
fastapi
uvicorn
requests
gtts
python-dotenv
streamlit
python-multipart

ğŸ§  How It Works

User uploads an image on the Streamlit UI

Image is sent to the FastAPI backend

The backend sends the image (base64 encoded) to OpenRouter

The LLM generates a natural English caption

Caption text is passed to gTTS

The app returns the caption and the generated voice file

ğŸ› ï¸ Future Improvements

ğŸ™ï¸ Add custom voice styles (ElevenLabs API)

ğŸ–‹ï¸ Allow multiple caption styles (short, funny, poetic)

ğŸ§± Add database for storing past captions

ğŸŒ Deploy on Render / Hugging Face Spaces

ğŸ§‘â€ğŸ’» Author: Chandan Kheto
ğŸš€ AI Developer
ğŸŒŸ Support
If you found this project useful, please â­ the repo â€” it motivates continued updates!
